{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting for model openl3\n",
      "and saving them into figures/2d_plots/openl3\n",
      "Plotting for model wav2vec\n",
      "and saving them into figures/2d_plots/wav2vec\n",
      "Plotting for model yamnet\n",
      "and saving them into figures/2d_plots/yamnet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "from utils import load_embeddings, load_labels, compute_all_labels, aggregate_embeddings, aggregate_labels\n",
    "\n",
    "\n",
    "# t-sne parameters\n",
    "PARAMS_TSNE = {\n",
    "    \"yamnet\":{ \"peplexity\": 30, \"early_exaggeration\": 5},\n",
    "    \"openl3\":{ \"peplexity\": 3, \"early_exaggeration\": 9},\n",
    "    \"wav2vec\":{ \"peplexity\": 80, \"early_exaggeration\": 12},\n",
    "}\n",
    "\n",
    "# Define colors\n",
    "colors = {\n",
    "    'Human': (229, 27, 32),\n",
    "    'Human/Cough': (101, 19, 17),\n",
    "    'Human/Movement': (248, 201, 193),\n",
    "    'Human/Movement/Steps': (248, 201, 193),\n",
    "    'Human/Music': (234, 105, 104),\n",
    "    'Human/Voice': (178, 28, 28),\n",
    "    'Industrial': (32, 75, 155),\n",
    "    'Industrial/Construction': (134, 144, 200),\n",
    "    'Industrial/Industry': (110, 109, 143),\n",
    "    'Industrial/Vacuum': (204, 202, 216),\n",
    "    'Industrial/Ventilation': (69, 74, 113),\n",
    "    'Nature': (101, 179, 46),\n",
    "    'Nature/Animals': (142, 194, 87),\n",
    "    'Nature/Animals/Bird': (167, 206, 123),\n",
    "    'Nature/Animals/Cat': (106, 138, 93),\n",
    "    'Nature/Animals/Cricket': (66, 117, 63),\n",
    "    'Nature/Animals/Dog': (162, 208, 162),\n",
    "    'Nature/Animals/Sheep': (186, 191, 162),\n",
    "    'Nature/Elements': (39, 53, 29),\n",
    "    'Nature/Elements/Thunder': (110, 123, 102), \n",
    "    'Nature/Elements/Water': (97, 101, 66),\n",
    "    'Nature/Elements/Wind': (42, 76, 38),\n",
    "    'Nature/Vegetation': (72, 129, 49),\n",
    "    'Signals': (238, 115, 22), \n",
    "    'Signals/Alarm': (242, 145, 73),\n",
    "    'Signals/Bells': (174, 86, 22),\n",
    "    'Signals/Klaxon': (251, 205, 169),\n",
    "    'Signals/Siren': (206, 149, 103),\n",
    "    'Things': (251, 224, 23),\n",
    "    'Things/Ball': (253, 242, 184),\n",
    "    'Things/Blind': (252, 243, 162),\n",
    "    'Things/Door': (252, 248, 198),\n",
    "    'Things/Movement': (252, 229, 91),\n",
    "    'Things/Trolley': (251, 224, 50),\n",
    "    'Transport': (45, 188, 238),\n",
    "    'Transport/Motorized': (91, 153, 186),\n",
    "    'Transport/Motorized/Air': (23, 180, 233),\n",
    "    'Transport/Motorized/Rail': (139, 176, 203),\n",
    "    'Transport/Motorized/Road': (23, 131, 170),\n",
    "    'Transport/Non-motorized': (154, 211, 243)\n",
    "}\n",
    "colors = {k: tuple([c / 255 for c in v]) for k, v in colors.items()}\n",
    "\n",
    "\n",
    "IMAGE_FOLDER = \"figures/2d_plots\"\n",
    "if not os.path.exists(IMAGE_FOLDER):\n",
    "    os.makedirs(IMAGE_FOLDER)\n",
    "\n",
    "DATA_FOLDER: str = \"data\"\n",
    "EMB_FOLDER: str = \"data/embeddings\"\n",
    "\n",
    "loaded_embeddings = load_embeddings(EMB_FOLDER)\n",
    "labels = load_labels(DATA_FOLDER)\n",
    "all_labels = compute_all_labels(labels)\n",
    "\n",
    "models = loaded_embeddings.keys()\n",
    "datasets = labels.keys()\n",
    "\n",
    "# let's modify embeddings to be {model: {dataset: np.array (total_frames, features)}}\n",
    "# and labels to be {dataset: [list (tot n frames) of lists (labels in frame)]}\n",
    "loaded_embeddings = aggregate_embeddings(loaded_embeddings)\n",
    "labels = aggregate_labels(labels)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(18, 16), dpi=300)\n",
    "\n",
    "for j, model in enumerate(models):\n",
    "    image_folder = os.path.join(IMAGE_FOLDER, model)\n",
    "    if not os.path.exists(image_folder):\n",
    "        os.makedirs(image_folder)\n",
    "\n",
    "    print(f\"Plotting for model {model}\")\n",
    "    print(f\"and saving them into {image_folder}\")\n",
    "    \n",
    "    # we want a single array for every emb of the model (i.e., for each dataset)\n",
    "    # and a list of list of labels, w same length as emb.shape[0].\n",
    "    # Also, to do the plots, we need a dict {dataset: (start_idx, end_idx)}.\n",
    "    # We will compute it while concatenating the embeddings\n",
    "    idxs = {}\n",
    "    start, end = 0, 0\n",
    "    model_emb = []\n",
    "    for dataset in datasets:\n",
    "        e = loaded_embeddings[model][dataset]\n",
    "        end += e.shape[0]\n",
    "        idxs[dataset] = (start, end)\n",
    "        start = end\n",
    "\n",
    "        model_emb.append(e)\n",
    "    model_emb = np.concatenate(model_emb)\n",
    "\n",
    "    model_labels = []\n",
    "    for dataset in datasets:\n",
    "        model_labels.extend(labels[dataset])\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    pca_data = pca.fit_transform(model_emb)\n",
    "    # compute tsne\n",
    "    perpl = PARAMS_TSNE[model][\"peplexity\"]\n",
    "    early_ex = PARAMS_TSNE[model][\"early_exaggeration\"]\n",
    "    tsne = TSNE(n_components=2, perplexity=perpl, early_exaggeration=early_ex)\n",
    "    tsne_data = tsne.fit_transform(pca_data)\n",
    "    # we can plot\n",
    "    pre_trained_model = model\n",
    "    size = 3\n",
    "    alpha = 0.3\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        start, end = idxs[dataset]\n",
    "        data_subset = tsne_data[start:end]\n",
    "        lab_list_subset = model_labels[start:end]\n",
    "        for lab in all_labels:\n",
    "            lab_idx = [l_i for l_i, l in enumerate(lab_list_subset) if lab in l]\n",
    "            if len(lab_idx) == 0:\n",
    "                continue\n",
    "            axs[j, i].scatter(\n",
    "                x=data_subset[lab_idx, 0],\n",
    "                y=data_subset[lab_idx, 1],\n",
    "                label=lab,\n",
    "                color=colors[lab],\n",
    "                s=size,\n",
    "                alpha=alpha,\n",
    "            )\n",
    "            \n",
    "            #title1 = \"Titolo linea 1\"\n",
    "            #title2 = \"Titolo linea 2\"\n",
    "\n",
    "            #ax.text(.5, 1.05, title1, horizontalalignment='center', transform=ax.transAxes, fontsize=14, fontweight='bold')\n",
    "            #ax.text(.5, 1.01, title2, horizontalalignment='center', transform=ax.transAxes, fontsize=12)\n",
    "\n",
    "            #ax.plot([1, 2, 3, 4], [1, 4, 2, 3])\n",
    "            #plt.show()\n",
    "\n",
    "        #axs[j, i].set_title(dataset.replace(\"_\", \" \").title(), fontsize=18, pad=15)\n",
    "        axs[j, i].text(.5, 1.02, dataset.replace(\"_\", \" \").title(), horizontalalignment='center', fontsize=18, transform=axs[j, i].transAxes)\n",
    "        if i == 1:\n",
    "            suptitle = \"c) YAMNet\" if pre_trained_model == \"yamnet\" else \"a) OpenL3\" if pre_trained_model == \"openl3\" else \"b) Wav2Vec\"\n",
    "            axs[j, i].text(.5, 1.1, suptitle, horizontalalignment='center', fontsize=22, fontweight='bold', transform=axs[j, i].transAxes)\n",
    "\n",
    "# The following two lines generate custom fake lines that will be used as legend entries:\n",
    "colors_to_plot = {k: v for k, v in colors.items() if k in all_labels}\n",
    "markers = [plt.Line2D([0,0],[0,0],color=color, marker='o', linestyle='') for color in colors_to_plot.values()]\n",
    "fig.legend(markers, colors_to_plot.keys(), numpoints=1, loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=7, markerscale=1)\n",
    "\n",
    "fig.subplots_adjust(hspace = 0.5)\n",
    "plt.tight_layout()\n",
    "model_folder = os.path.join(image_folder, 'tsne')\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "plt.savefig(\"2demb.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
